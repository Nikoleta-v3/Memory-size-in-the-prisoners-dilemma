\documentclass[10pt]{article}

% Manage page layout
\usepackage[margin=2.5cm, includefoot, footskip=30pt]{geometry}
\pagestyle{plain}
\setlength{\parindent}{0em}
\setlength{\parskip}{1em}
\renewcommand{\baselinestretch}{1}

%%%%%%%PACKAGES HERE%%%%%%%
\usepackage{tikz}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{standalone}
\usepackage{booktabs}
\usepackage{algorithm, setspace}
\usepackage[noend]{algpseudocode}

\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother

\newcommand{\R}{\mathbb{R}}
\newtheorem{theorem}{Theorem}
\usetikzlibrary{decorations.pathmorphing, decorations.pathreplacing, angles,
                quotes, calc, er, positioning}

\newtheorem{lemma}[theorem]{Lemma}
\def\arraystretch{1.5}

%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Stability of defection, optimisation of strategies and the limits of
       memory in the Prisoner's Dilemma.}
\author{Nikoleta E. Glynatsi \and Vincent A. Knight}
\date{}

\begin{document}

\maketitle

\begin{abstract}
    In this manuscript we build upon a framework provided in 1989 to study best
    responses in the well known memory one strategies of the Iterated Prisoner's
    Dilemma. The aim of this work is to construct a compact way of identifying
    best responses of short memory strategies and to show their limitations in
    multi-opponent interactions. A number of theoretic results are presented.
    %TODO: Expand when we get results
\end{abstract}

\section{Introduction}\label{section:introduction}

The Prisoner's Dilemma (PD) is a two player game used in understanding the
evolution of co-operative behaviour. Each player has two options, to cooperate
(C) or to defect (D). The decisions are made simultaneously and independently.
The normal form representation of the game is given by:

\begin{equation}\label{equ:pd_definition}
    S_p =
    \begin{pmatrix}
        R & S  \\
        T & P
    \end{pmatrix}
    \quad
    S_q =
    \begin{pmatrix}
        R & T  \\
        S & P
    \end{pmatrix}
\end{equation}

where \(S_p\) represents the utilities of the row player and \(S_q\) the
utilities of the column player. The payoffs, \((R, P, S, T)\), are constrained
by equations (\ref{eq:pd_constrain_one}) and~(\ref{eq:pd_constrain_two}).
Constraint (\ref{eq:pd_constrain_one}) ensures that
defection dominates cooperation and constraint (\ref{eq:pd_constrain_two})
ensures that there is a dilemma; the sum of the utilities for both players is
better when both choose to cooperate. The
most common values used in the literature are
\((3, 1, 0, 5)\)~\cite{Axelrod1981}.

\begin{equation}\label{eq:pd_constrain_one}
    T > R > P > S
\end{equation}

\begin{equation}\label{eq:pd_constrain_two}
    2R > T + S
\end{equation}

The PD is a one shot game, however it is commonly studied in a manner where the
history of the interactions matter. The repeated form of the game is called the
Iterated Prisoner's Dilemma (IPD) and in the 1980s, % TODO Add RAND reference
following the work of
\cite{Axelrod1980a, Axelrod1980b} it attracted the attention of the scientific
community.

In~\cite{Axelrod1980a} and~\cite{Axelrod1980b}, the first well known computer
tournaments of the IPD were performed. A total of 13 and 63 strategies were
submitted in computer code and competed against each other in a round robin
tournament. All contestants competed against each other, a copy of themselves
and a random strategy. The winner was decided on the average score a strategy
achieved and not the total number of wins. How many turns of history that a
strategy would use, the memory size, was a result of the particular strategic
decisions made by the author.

The winning strategy of both tournaments was a strategy called Tit for Tat. Tit
for Tat is a strategy which starts by cooperating and then mimics the last move
of it's opponent. This is a strategy which makes use of the previous move of the
opponent only, this type of strategy is called \textit{reactive}.
In~\cite{Nowak1989} a framework for studying such strategies was introduced.
This was later used to introduce well known reactive strategies such as Generous
Tit For Tat~\cite{Nowak1990}.

Reactive strategies are a subset of so called \textit{memory one} strategies.
Memory one strategies similarly are only concerned with the previous turn.
However, they take into consideration both players' recent moves to decide on an
action. Several successful memory one strategies are found in the literature,
for example Pavlov~\cite{Nowak1993}.

A well known set of memory on strategies was introduced in~\cite{Press2012},
these were called zero determinant (ZD) strategies. The ZD strategies manage to
force a linear relationship between the score of the strategy and the opponent.
According to~\cite{Press2012} the ZD strategies can dominate any evolutionary
opponent in pairwise interactions by using a single turn of memory. Thus, in a
sense this work questioned the importance of memory and the sophistication
required/necessary for evolutionary fixation.

These ZD strategies attracted a lot of attention. It was stated that ``Press and
Dyson have fundamentally changed the viewpoint on the Prisoner's
Dilemma''~\cite{Stewart2012}. In~\cite{Stewart2012} a very similar tournament to
Axelrod's tournament is run including ZD strategies and a new set of ZD
strategies. One specific advantage of memory one strategies is
their mathematical tractability.  As described in
Section~\ref{section:utility_against_mem_one} they can be represented completely
as an vector of \(\R^{4}\).

Even so, ZD and memory one strategies have also received criticism.
In~\cite{Harper2015},
the `memory of a strategy does not matter' statement was questioned. A set of more
complex strategies, strategies that take in account the entire history set of the
game, were trained and proven to be more robust against multiple opponents.

The purpose of this work is to consider a given memory one strategy in a similar
fashion to~\cite{Press2012}. However whilst~\cite{Press2012} found a way for a
player to manipulate a given opponent, this work will consider a
multidimensional optimisation approach to identify the best response to a group
of opponents. In essence the aim is to produce a compact method of identifying
the best memory one strategy against a given opponent.

In the second part of this manuscript we explore the limitation of these best
response strategies. This is achieved by comparing the performance of an optimal
memory one strategy, for a given environment, with the performance of a more
complex strategy that has a larger memory.

One particular benefit of this analysis is the identification of conditions for
which defection is a best response. Thus, identifying environments for which
cooperation can not occur.

\section{The utility against memory one players}\label{section:utility_against_mem_one}

In~\cite{Press2012} it
is stated that if a strategy is concerned with only the outcome of a single turn
then there are four possible `states' the strategy could be in. These are
\(CC, CD, DC,CC\). A memory one strategy is denoted by the probabilities of
cooperating after each of these states,
\(p=(p_1, p_2, p_3, p_4) \in \R_{[0,1]} ^ 4\).
A diagrammatic representation of such a strategy is given in
Figure~\ref{fig:diagram_mem_one}.

\begin{figure}
    \centering
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includestandalone[width=.65\textwidth]{tex/states}
        \subcaption{Diagrammatic representation of a memory one strategy.}
        \label{fig:diagram_mem_one}
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includestandalone[width=.88\textwidth]{tex/markov_chain}
        \subcaption{Markov chain on a PD game.}
        \label{fig:markov_chain}
    \end{subfigure}
\end{figure}

Moreover, if two memory one players are moving from state to state
this can be modelled as a Markov process. A diagrammatic
representation of the Markov chain is shown in Figure~\ref{fig:markov_chain}.
The corresponding transition matrix \(M\) given by:

\begin{equation}\label{eq:m_matrix}
    \input{tex/m_matrix.tex}.
\end{equation}

The long run steady state probability \(v\) is the solution to
\(v M = v\)
This corresponds to finding the unit eigenvector of \(M\) and a closed form
for \(v\) can be found (given in the Appendix). %TODO include Appendix
Combining the stationary vector \(v\) with the payoff matrices of
equation~(\ref{equ:pd_definition})
allows us to retrieve the expected payoffs for each player. Thus, the utility for
player \(p\) against \(q\), denoted as \(u_q(p)\), is defined by,

\begin{equation}\label{eq:press_dyson_utility}
    u_q(p) = v \times (R, P, S, T).
\end{equation}

Here, to our knowledge, we present the first theoretical result which
concerns the form of \(u_q(p)\). That is that \(u_q(p)\) is given by a ratio of
two quadratic forms~\cite{kepner2011}, as presented by
Theorem~\ref{theorem:quadratic_form_u}.

\begin{theorem}\label{theorem:quadratic_form_u}
    The expected utility of a memory one strategy \(p\in\mathbb{R}_{[0,1]}^4\)
    against a memory one opponent strategy \(q\in\mathbb{R}_{[0,1]}^4\), denoted
    as \(u_q(p)\), can be written as a ratio of two quadratic forms:

    \begin{equation}\label{eq:optimisation_quadratic}
    u_q(p) = \frac{\frac{1}{2}pQp^T + cp + a}
                {\frac{1}{2}p\bar{Q}p^T + \bar{c}p + \bar{a}},
    \end{equation}
    where \(Q, \bar{Q}\) \(\in \R^{4\times4}\) are matrices defined by the
    transition probabilities of the opponent \(q_1, q_2, q_3, q_4\) as follows:

    \begin{center}
    \begin{equation}
    \resizebox{0.9\linewidth}{!}{\arraycolsep=2.5pt%
    \boldmath\(
    Q = \input{tex/q_numerator}\)},
    \end{equation}
    \begin{equation}\label{eq:q_bar_matrix}
    \resizebox{0.8\linewidth}{!}{\arraycolsep=2.5pt%
    \boldmath\(
    \bar{Q} =  \input{tex/q_denominator}\)}.
    \end{equation}
    \end{center}

    \(c \text{ and } \bar{c}\) \(\in \R^{4 \times 1}\) are similarly defined by:

    \begin{equation}\label{eq:q_matrix_numerator}
    \resizebox{0.3\linewidth}{!}{\arraycolsep=2.5pt%
    \boldmath\(c = \input{tex/c_numerator}\),}
    \end{equation}
    \begin{equation}\label{eq:q_matrix_denominator}
    \resizebox{0.3\linewidth}{!}{\arraycolsep=2.5pt%
    \boldmath\(\bar{c} = \input{tex/c_denominator}\).
    }
    \end{equation}

    and \(a = \input{tex/numerator_constant}\) and
    \(\bar{a} = \input{tex/denominator_constant}\).
\end{theorem}

Proof: The proof is given in Appendix. %TODO write proof

Figure~\ref{fig:analytical_simulated} indicates that the formulation of \(u_q(p)\)
as a quadratic ratio successfully captures the simulated behaviour. A data set
offering further validation is available at. %TODO archive data
The simulated utility, denoted
as \(U_q(p)\) has been calculated using~\cite{axelrodproject},  an open research
framework for the study of the IPD and is described in~\cite{Knight2016}. Note that
when referring to \(U_q(p)\) here onwards we mean the simulated utility calculated
with~\cite{axelrodproject}.

\begin{figure}[!htbp]
\begin{center}
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\linewidth]{img/validation_img_two.png}
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\linewidth]{img/validation_img_three.png}
    \end{subfigure}
\end{center}
\caption{Differences between simulated and analytical results for
\(q = (\frac{1}{3}, \frac{1}{3}, \frac{1}{3}, q_4)\).}
\label{fig:analytical_simulated}
\end{figure}

Theorem~\ref{theorem:quadratic_form_u} can be extended to consider multiple
opponents
The IPD is commonly studied in tournaments and or Moran Processes where a
strategy interacts
with a number of opponents. The payoff of a player is then given by the average
payoffs the against each opponent.
More specifically the expected utility of a memory one strategy
against a \(N\) number of opponents is given by Theorem~\ref{theorem:tournament_utility}.

\begin{theorem}\label{theorem:tournament_utility}
    The expected utility of a memory one strategy \(p\in\mathbb{R}_{[0,1]}^4\)
    against a group of opponents \(q^{(1)}, q^{(2)}, \dots, q^{(N)}\), denoted
    as \(\frac{1}{N} \sum\limits_{i=1} ^ {N} {u_q}^{(i)} (p)\) is given by:

    \begin{equation}\label{eq:tournament_utility}
        \frac{1}{N} \sum\limits_{i=1} ^ {N} {u_q}^{(i)} (p) = \frac{1}{N}
        \frac{\sum\limits_{i=1} ^ {N} (\frac{1}{2} pQ^{(i)} p^T + c^{(i)} p + a^ {(i)})
        \prod\limits_{\tiny\begin{array}{l} j=1 \\ j \neq i \end{array}} ^
        N (\frac{1}{2} p\bar{Q}^{(i)} p^T + \bar{c}^{(i)} p + \bar{a}^ {(i)})}
        {\prod\limits_{i=1} ^ N (\frac{1}{2} p\bar{Q}^{(i)} p^T + \bar{c}^{(i)} p + \bar{a}^ {(i)})}.
    \end{equation}
\end{theorem}

As an illustration, Theorem~\ref{theorem:tournament_utility} is used to calculate
he theoretical payoffs of several memory one strategies against
a set of 10 opponents. The opponents used are the memory one strategies for the
tournament
conducted in~\cite{Stewart2012}. This tournament is also simulated as before
The names and a small explanation of the strategic rules are
given in Appendix~\ref{appendix:tables}.
The values of \(\frac{1}{N} \sum\limits_{i=1} ^ {N} u_{q ^{(i)}} (p)\) and
\(\frac{1}{N} \sum\limits_{i=1} ^ {N} U_{q ^{(i)}} (p)\) match (Table~\ref{table:list_stewart_plotkin}),
% TODO I wonder if we drop the \frac{1}{N} (it's not really required)

\begin{table}[htbp]
    \begin{center}
    \input{tex/stewart_results.txt}
    \end{center}
    \caption{Results of memory one strategies against the strategies in Table~\ref{table:list_stewart_plotkin}.}
    \label{table:list_stewart_plotkin}
\end{table}

% TODO This needs to be either a single number: the utility in the tournament
% **OR** parametrize the strategies (change 0 <= p_1 <= 1) and get a 1
% dimensional plot against one of those parameters.

Note that the utility against a group of strategies can not be captured by
the utility against the mean opponent.

\begin{equation}\label{eq:tournament_hypothesis}
    \frac{1}{N} \sum_{i=1} ^ {N} {u_q}^{(i)} (p) \neq
      u_{\frac {1}{N} \sum\limits_{i=1} ^ N q^{(i)}}(p).
\end{equation}

This is illustrated in Figure~\ref{fig:hypothesis}.

\begin{figure}[!htbp]
    \begin{center}
            \includegraphics[width=\linewidth]{img/mean_vs_average_two.png}
    \end{center}
    \caption{Plotting the difference of the average utility against ten
    opponents versus the utility against the average of the ten strategies.}
    \label{fig:hypothesis}
\end{figure}


The analytical formulation of Theorem~\ref{theorem:tournament_utility} will be
used in the following sections to explore the best response to memory one
strategies.

\section{Best responses to memory one players}\label{section:best_response_mem_one}

Identifying the \textbf{best response} to a group of memory one strategies  will
be considered as a multi dimensional optimisation problem, where a memory one
strategy \(p\) aims to optimise
\( \frac{1}{N} \sum u_{q ^{(i)}} (p)\) against a set opponents
\(\{q^{(1)}, q^{(2)}, \dots, q^{(N)} \}\).

The decision variable is the vector \(p\) and the solitary constraint is
that \(p \in \R^4_{[0, 1]} \).
The optimisation problem is given by~(\ref{eq:mo_tournament_optimisation}).

\begin{equation}\label{eq:mo_tournament_optimisation}
    \begin{aligned}
    \max_p: & \ \sum_{i=1} ^ {N} {u_q}^{(i)} (p)
    \\
    \text{such that}: & \ p \in \R_{[0, 1]}
    \end{aligned}
\end{equation}

Optimising this particular ratio of quadratic forms is not trivial.
It can be verified empirically for the case of a single opponent that there
exist at
least one point for which the definition of concavity does not hold.

There is some work on the optimisation on non concave ratios of of quadratic forms
\cite{Beck2009, Hongyan2014}, however in these both the numerator and the denominator
of the fractional problem were concave which is not true for here.
These results are established in Theorem~\ref{theorem:concavity}.

\begin{theorem}\label{theorem:concavity}
    The utility of a player \(p\) against an opponent \(q\), \(u_q (p)\) given by
    (\ref{eq:optimisation_quadratic}), is not concave. Furthermore neither the
    numeration or the denominator of (\ref{eq:optimisation_quadratic}), are concave.
\end{theorem}

\begin{proof}
    A function \(f(x)\) is said to be concave on an interval \([a, b]\) if, for any
    points \(x_1\) and \(x_2 \in [a, b]\), the function \(-f(x)\) is convex on that
    interval.

    A function \(f(x)\) is convex on an interval \([a, b]\) if for any two
    points \(x_1\) and \(x_2\) in \([a, b]\) and any \(\lambda\) where \(0 < \lambda < 1\),

    \begin{equation}\label{def:convex}
    f (\lambda x_1 + (1 - \lambda )x_2 ) \leq \lambda f (x_1 ) + (1 - \lambda )f (x_2 ).
    \end{equation}

    Let \(f\) be
    \(u_{(\frac{1}{3}, \frac{1}{3}, \frac{1}{3}, \frac{1}{3})}\) it can be shown
    that
    for \(x_1 = (\frac{1}{4}, \frac{1}{2}, \frac{1}{5} , \frac{1}{2}),
    x_2 = (\frac{8}{10}, \frac{1}{2}, \frac{9}{10} , \frac{7}{10})\) and
    \(\lambda=\frac{1}{10}\)
    condition (\ref{def:convex}) does not hold as: \(1.49 \geq 1.48\).

    In~\cite{Anton2014} it is stated that a quadratic form will
    be concave if and only if it's symmetric matrix is negative semi definite.
    A matrix\(A\) is semi-negative definite if:

    \begin{equation}\label{def:semi_negative}
    |A|_i \leq 0 \text{ for } i \text{ is odd and } |A|_i \geq 0  \text{ for } i
    \text{ is even.}
    \end{equation}

    For both \(Q\) and \(\bar{Q}\) it is exhibited that for \(i=2\) (odd):
    % TODO What do you mean by "exhibited"?

    \[|Q|_2 = - \left(q_{1} - q_{3}\right)^{2} \left(q_{2} - 5 q_{4} - 1\right)^{2},\]
    \[|\bar{Q}|_2 =- \left(q_{1} - q_{3}\right)^{2} \left(q_{2} - q_{4} - 1\right)^{2}\]

    both determinants are negative, thus the concavity condition
    (\ref{def:semi_negative})
    fails for both quadratic forms.
\end{proof}

The non concavity of \(u(p)\) indicates multiple local optimal points.
The approach taken here is to introduce a compact way of constructing
the candidate set of all local optimal points. Once
the set is defined the point that maximises (\ref{eq:tournament_utility})
corresponds to the best response strategy, this approach transforms the
continuous optimisation problem in to a discrete problem.

The problem considered is a bounded because \(p \in \R^4_{[0, 1]}\).
The candidate solutions will exist either at the boundaries
of the feasible solution space, or within that space. The method of Lagrange
Multipliers~\cite{bertsekas2014} and Karush-Kuhn-Tucker
conditions~\cite{Giorgi2016} are based on this. The Karush-Kuhn-Tucker
conditions are used here because the constraints are inequalities.

The above discussion leads to Lemma~\ref{lemma:memone_group_best_response} which
presents the best response to a group of opponents.

\begin{lemma}\label{lemma:memone_group_best_response}

    The optimal behaviour of a memory one strategy player
    \(p^* \in \R_{[0, 1]} ^ 4\)
    against a set of \(N\) opponents \(\{q^{(1)}, q^{(2)}, \dots, q^{(N)} \}\)
    for \(q^{(i)} \in \R_{[0, 1]} ^ 4\) is established by:

    \[p^* = \textnormal{argmax}(\sum\limits_{i=1} ^ N  u_q(p)), \ p \in S_q,\]

    where the set \(S_q\) is defined as

    \[
        S_q =
        \left\{p \in \mathbb{R} ^ 4\;|\;
            \begin{array}{c}
                p_i \in{0, 1}\text{ or }F_i(p_i) = 0\\
                \prod\limits_{i=1} ^ N Q_{D}^{(i)} \neq 0
            \end{array}
            % TODO We should definitely talk this one over.
            \text{ for all } i\in\{1, 2, 3, 4\}
        \right\}
    \]


    where,
    % TODO I am not sure if F is a good choice
    \begin{equation}\label{eq:group_derivative_numerator_condition}
    F=(\sum\limits_{i=1} ^ {N} Q_{N}^{(i)'} \prod_{\substack{j=1 \\ j \neq i}} ^ N Q_{D}^{(i)}
     + \sum\limits_{i=1} ^ {N} Q_{D}^{(i)'} \sum_{\substack{j=1 \\ j \neq i}} ^ {N} Q_{N}^{(i)}
    \prod_{\substack{j=1 \\ j \neq \{i, j\}}} ^ N Q_{D}^{(i)}) \times
    \prod\limits_{i=1} ^ N Q_{D}^{(i)} - (\sum\limits_{i=1} ^ {N} Q_{D}^{(i)'}
    \prod_{\substack{j=1 \\ j \neq i}} ^ N Q_{D}^{(i)}) \times
    (\sum\limits_{i=1} ^ {N} Q_{N}^{(i)} \prod_{\substack{j=1 \\ j \neq i}} ^ N Q_{D}^{(i)})
    \end{equation}

    and,

    \begin{align*}
        Q_{N}^{(i) } & = \frac{1}{2} pQ^{(i)} p^T + c^{(i)} p + a^ {(i)}, \\
        Q_{N}^{(i)'} & =  pQ^{(i)} + c^{(i)}, \\
        Q_{D}^{(i) } & = \frac{1}{2} p\bar{Q}^{(i)} p^T + \bar{c}^{(i)} p + \bar{a}^ {(i)}, \\
        Q_{D}^{(i)'} & =  p\bar{Q}^{(i)} + \bar{c}^{(i)}. \\
    \end{align*}
\end{lemma}

\begin{proof}
    The best response of a memory one strategy against a group of memory
    one strategies can captured by a candidate set of behaviours. This candidate
    set is constructed by considering behaviours where any or all of \(p_1, p_2, p_3, p_4\)
    are \(\in \{0, 1\}\) and the rest or all of \(p_1, p_2, p_3, p_4\) are given by
    roots of the partial derivatives.

    Note that for \(p_i \in \{0, 1\}\) we consider the roots of the partial derivatives
    for \(p_j \neq p_i\) for \(i,j \in [1, 4]\).

    The derivatives, \(\frac{d\sum u}{dp}\), are given by,

    {\scriptsize
    \begin{align}\label{eq:mo_tournament_derivative}
        \frac{d}{dp} \sum\limits_{i=1} ^ {N} {u_q}^{(i)} (p) & = \nonumber \\
        & =\frac{
        (\sum\limits_{i=1} ^ {N} Q_{N}^{(i)'} \prod_{\substack{j=1 \\ j \neq i}} ^ N Q_{D}^{(i)}
        + \sum\limits_{i=1} ^ {N} Q_{D}^{(i)'} \sum_{\substack{j=1 \\ j \neq i}} ^ {N} Q_{N}^{(i)}
       \prod_{\substack{j=1 \\ j \neq \{i, j\}}} ^ N Q_{D}^{(i)}) \times
       \prod\limits_{i=1} ^ N Q_{D}^{(i)} - (\sum\limits_{i=1} ^ {N} Q_{D}^{(i)'}
       \prod_{\substack{j=1 \\ j \neq i}} ^ N Q_{D}^{(i)}) \times
       (\sum\limits_{i=1} ^ {N} Q_{N}^{(i)} \prod_{\substack{j=1 \\ j \neq i}} ^ N Q_{D}^{(i)})}
        {(\prod\limits_{i=1} ^ N Q_{D}^{(i)})^{2}}
    \end{align}
    }

    For equation~\ref{eq:mo_tournament_derivative} to be zero, the numerator must fall
    to zero and the denominator can not nullified.

    One the candidate set is constructed each point is evaluated using equation
    (\ref{eq:tournament_utility}). The point with the maximum utility is selected.
\end{proof}

A special case of Lemma~\ref{lemma:memone_group_best_response} is for \(N=1\),
thus when a strategy plays against a single opponent. In this case the formulation
of Theorem~\ref{theorem:quadratic_form_u} is used and the best response is captured
by Lemma~\ref{lemma:memone_best_response}.

\begin{lemma}\label{lemma:memone_best_response}
    The optimal behaviour of a memory one strategy player \(p^* \in \R_{[0, 1]} ^ 4\)
    against a given opponent \(q \in \R_{[0, 1]} ^ 4\) is given by:

    \[p^* = \textnormal{argmax}(u_q(p)), \ p \in S_q,\]

    where the set \(S_q\) is defined as

    \[S_q = \{0, \bar{p}_i, 1 \}^4 \text{ for } i \in \R,\]

    where any \(\bar{p}\) satisfy condition (\ref{eq:cases_mem_one}). Note that now
    the numerators of the partial derivatives, (\ref{eq:group_derivative_numerator_condition}),
    are given by

    {\small
    \begin{equation}\label{eq:derivative_numerator_condition}
        (pQ + c) ( \frac{1}{2} p  \bar{Q}  p^T + \bar{c}  p + \bar{a})
        - (p\bar{Q} + \bar{c})( \frac{1}{2} p  Q  p^T + c p + a)
    \end{equation}}

    and (\ref{eq:group_derivative_denominator_condition}) is re-written as:

    {\small
    \begin{equation}\label{eq:derivative_denominator_condition}
        \frac{1}{2} p  \bar{Q}  p^T + \bar{c}  p + \bar{a} \neq 0
    \end{equation}}
\end{lemma}

\begin{proof} The best response of a memory one strategy against another memory
    one strategy can captured by a candidate set of behaviours. This candidate
    set is constructed by considering behaviours where any or all of \(p_1, p_2, p_3, p_4\)
    are \(\in \{0, 1\}\) and the rest or all of \(p_1, p_2, p_3, p_4\) are given by
    roots of the partial derivatives.

    Note that for \(p_i \in \{0, 1\}\) we consider the roots of the partial derivatives
    for \(p_j \neq p_i\) for \(i,j \in [1, 4]\).

    The derivatives, \(\frac{du}{dp}\), are given by,

    \begin{equation}\label{eq:mo_derivative}
        \frac{du_q (p)}{dp}  = \frac{(pQ + c) ( \frac{1}{2} p  \bar{Q}  p^T + \bar{c}  p + \bar{a})
        - (p\bar{Q} + \bar{c})( \frac{1}{2} p  Q  p^T + c p + a)}
          {( \frac{1}{2} p  \bar{Q}  p^T + \bar{c}  p + \bar{a})^2} \\
    \end{equation}


    For equation~\ref{eq:mo_tournament_derivative} to be zero, the numerator must fall
    to zero and the denominator can not be zero.
\end{proof}

Equations (\ref{eq:group_derivative_numerator_condition}) and
(\ref{eq:derivative_numerator_condition})
are systems of at most \(4\) polynomials and the degree of the polynomials is gradually increasing
every time an extra opponent is taken into account. Solving system of polynomials corresponds
to the calculation of a resultant and for large systems these quickly become intractable.
% TODO Add a reference here about resultants.
Because of that no further analytical consideration is given to problems described
here.

Theorems~\ref{} can also be used to identify if a strategy is a best response.
% TODO Add an example where we check if `extort-2` is a best response to the
% tournament of S&P.

Lemma~\ref{lemma:memone_group_best_response} and Theorem~\ref{theorem:tournament_utility}
will now be used to give a list of particular best response results.

\subsection{Reactive Strategies}\label{section:reactive_analytical}

The first constrained case considered here is that of the reactive strategies.
Reactive strategies are a set of memory one strategies where they only take into
account the opponent's previous moves. As described in Section~\ref{section:introduction}
Tit for Tat is a reactive strategy. The optimisation problem of (\ref{eq:mo_tournament_optimisation})
now has an extra constraint and is re written as,

\begin{equation}\label{eq:reactive_tournament_optimisation}
\begin{aligned}
\max_p: & \ \sum_{i=1} ^ N u_q(p)
\\
\text{such that}: & \ p_1 = p_3 \text{ and } p_2 = p_4\\
    & \ p_1, p_2 \in \R_{[0, 1]}.
\end{aligned}
\end{equation}

Reactive strategies allow us to study \(u_p\) as a function of two variables
\(p_1, p_2\) and the best reactive response against a group of opponents is captured by Lemma
\ref{lemma:reactive_group_best_response}.

\begin{lemma}\label{lemma:reactive_group_best_response}
    The optimal behaviour of a reactive player \(p^* \in \R_{[0, 1]} ^ 2\) against a set
    of \(N\) opponents \(\{q^{(1)}, q^{(2)}, \dots, q^{(N)} \}\) for \(q^{(i)} \in
    \R_{[0, 1]} ^ 4\) is given by:

    \[p^* = \textnormal{argmax}(\sum\limits_{i=1} ^ N  u_q(p)), \ p \in S_q,\]

    where the set \(S_q\) is defined as

    \[S_q = \{0, \bar{p_i}, 1 \} ^ 2 \text{ for } i \in \R,\]

    where \(\bar{p_i}\) satisfies one of the following cases:

    \begin{equation}\label{eq:cases_reactive}
        \left\{\begin{array}{lr}
        \frac{\sum u}{dp_{|p=p^*}} = 0, & \text{for } p^* \in \{\bar{p}_i\} ^ 4, \\
        \frac{\sum u}{dp_{1_{|p_1=p_1^*}}} = 0, & \text{for } p_1^* \in \{\bar{p}_i\}
        \text{ while } p_2 ^ * \in \{0, 1\},\\
        \frac{\sum u}{dp_{2_{|p_2=p_2^*}}} = 0, & \text{for } p_2^* \in \{\bar{p}_i\}
        \text{ while } p_1 ^ * \in \{0, 1\}.
        \end{array}\right.
    \end{equation}

    For cases (\ref{eq:cases_reactive}) to be true the numerator of the partial
    derivatives, given by (\ref{eq:group_derivative_numerator_condition}), must equal
    to zero and condition (\ref{eq:group_derivative_denominator_condition}) must hold.
\end{lemma}

Similarly to the memory one approach a special case for \(N=1\), against a single
memory one strategy, is applied to
Lemma~\ref{lemma:reactive_group_best_response}. The best response against a single
opponent is captured by Lemma~\ref{lemma:reactive_best_response}.

\begin{lemma}\label{lemma:reactive_best_response}
    The optimal behaviour of a reactive player \(p^* \in \R_{[0, 1]} ^ 2\) against a given
    opponent \(q \in \R_{[0, 1]} ^ 4\) is given by:

    \[p^* = \textnormal{argmax}(u_q(p)), \ p \in S_q,\]

    where the set \(S_q\) is defined as

    \[S_q = \{0, \bar{p_i}, 1 \} ^ 2 \text{ for } i \in \R,\]

    where \(\bar{p}_i\) satisfies any of (\ref{eq:cases_reactive}). Partial derivatives
    are now given by (\ref{eq:derivative_numerator_condition}) and
    (\ref{eq:derivative_denominator_condition}) must be true.
\end{lemma}

Note that now equation (\ref{eq:group_derivative_numerator_condition}) and (\ref{eq:derivative_numerator_condition})
correspond to systems of maximum 2 polynomials over 2 variables. Each polynomial is equivalent
to a partial derivative over \(p_1\) and \(p_2\). Several methods exist that allow
for the \(2\) polynomial systems to be solved analytically. In this work the results theory
is used to extract the roots from the partial derivatives.

Note that for pairwise interactions the maximum degree
of the polynomials is equal to \(2N\), however the degree increases as opponents
are introduced.

The resultant is a symmetric function of the roots of the polynomials of a system
and it can be expressed as a polynomial in the coefficients of the polynomials.
The resultant will equal zero if and only if the system has at least one common
root. Thus, the resultant becomes very useful in identifying whether common roots exist.

In this work the Sylvester's resultant~\cite{Akritas1991} denoted as (\(R_S\))
is considered. The Sylvester's resultant is used to solve system of a single
variable. However, for a system of two variables we solve over one variable and
the second is kept as a coefficient. Thus we can find the roots of the equations
and that is why the resultant is often refereed to as the eliminator.

In Appendix Algorithm~\ref{algo:reactive} describes the process and based on the
Algorithm several examples are performed. Illustrated by Figure~\ref{fig:reactive_pairwise_results}
are the results of these examples. The results suggest that the best response behaviour
is captured by our algorithm.

\begin{figure}
    \centering
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=.95\textwidth]{img/reactive_pairwise_one.pdf}
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=.95\textwidth]{img/reactive_pairwise_two.pdf}
    \end{subfigure}
    \caption{Numerical experiments for Algorithm~\ref{algo:reactive} for \(N=1\).}
    \label{fig:reactive_pairwise_results}
\end{figure}

\subsection{Purely random}\label{section:purely_analytical}

The next constrained problem to be explored is that of the purely random strategies.
Purely random strategies are a set of memory one strategies where the transition
probabilities of each state are the same. The optimisation problem of (\ref{eq:mo_tournament_optimisation})
now has an extra constraint and is re written as,

\begin{equation}\label{eq:random_optimisation}
\begin{aligned}
\max_p: & \ \frac{1}{N} \sum_{i=1} ^ {N} {u_q}^{(i)} (p)
\\
\text{such that}: & p_1 = p_2 = p_3 = p_4 = p \\
                  & p \in \R_{[0, 1]} \\
\end{aligned}
\end{equation}

and the exact optimal behaviour of purely random strategies is described in
Lemma~\ref{lemma:purely_optimisation}.

\begin{lemma}
    \label{lemma:purely_optimisation}
    The optimal behaviour of a \textbf{purely random} player \(p ^ * \in \R_{[0, 1]}\)
    in an \(N-\)memory one player tournament, \(\{q_{(1)}, q_{(2)} \dots,q_{(N)} \}
    \) for \(q_{(i)} \in \R_{[0, 1]} ^ 4\) is given by:

    \[p^* = \textnormal{argmax}(\sum_{i=1} ^ {N} {u_q}^{(i)} (p) ), \ p \in S_{q(i)},\]

    where the set \(S_{q}\) is defined as:

    \[S_{q} = \{0, \lambda_i, 1\},\text{ for } i \in [1, 2N]\]

    where \(\lambda_i\) are the eigenvalues of the companion matrix corresponding
    to the numerator of \[\frac{d}{dp} \sum_{i=1} ^ {N} {u_q}^{(i)} (p)\]

    for which
    \[\frac{d}{dp} \sum_{i=1} ^ {N} {u_q}^{(i)} (\lambda_j) = 0,\text{ for } j \in [1, 2N].\]
\end{lemma}

\begin{proof}
    The best behaviour of a purely random strategy against a set of opponents is
    captured by a set of potential best behaviours. For constructing this a set
    a similar as the ones described in previous sections is used.

    It is know that \(p ^ *\) will either be \(\in \{0, 1\}\) or \(p ^ *\) will because
    given by the roots of \(\frac{d}{dp} \sum\limits_{i=1} ^ {N} {u_q}^{(i)}(p)\).
    The roots of  \(\frac{d}{dp} \sum\limits_{i=1} ^ {N} {u_q}^{(i)} (p)\) are the roots
    only of the numerator, as the denominator can not be nullified.

    Studying equation (\ref{eq:optimisation_quadratic}) as a function of a single variable
    \(p\) it can be verified that the degree of the numerator is equal to\(2N\).
    Thus, the size of roots of the numerator is equal to \(2N\).

    The roots on the polynomial in this work will be calculated using a companion
    matrix method~\cite{Edelman1995}. This method allows the roots of the polynomial to
    be computed by calculating the eigenvalues of the corresponding companion
    matrix.

    The eigenvalues and the bounds compose the candidate set of solutions. The
    best response of a purely random player corresponds to the point that maximises
    (\ref{eq:optimisation_quadratic}).
\end{proof}

Lemma~\ref{lemma:purely_optimisation} can be further expanded to the case where \(N=1\).
Algorithm~\ref{algo:purely} describes the process of best purely random responses and it is
used for a number of empirical trials.
The results of these trials are illustrated in Figures~\ref{fig:purely_random_pairwise_results}
and \ref{fig:purely_random_tournament_results}. Figure~\ref{fig:purely_random_pairwise_results}
demonstrates Lemma~\ref{lemma:purely_optimisation} for \(N=1\) and
Figure~\ref{fig:purely_random_tournament_results} cases were \(N>1\).
It is evident that the optimal behaviour has been captured by our search algorithm.

\begin{figure}
    \centering
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=.95\textwidth]{img/purely_random_match_one.pdf}
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=.95\textwidth]{img/purely_random_match_two.pdf}
    \end{subfigure}
    \caption{Numerical experiments for Algorithm~\ref{algo:purely} for \(N=1\).}
    \label{fig:purely_random_pairwise_results}
\end{figure}

\begin{figure}
    \centering
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=.95\textwidth]{img/purely_random_tournament_one.pdf}
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
        \centering
        \includegraphics[width=.95\textwidth]{img/purely_random_tournament_two.pdf}
    \end{subfigure}
    \caption{Numerical experiments for Algorithm~\ref{algo:purely} for \(N>1\).}
    \label{fig:purely_random_tournament_results}
\end{figure}

Furthermore, for the case of the purely random players two more theoretical results
are discussed. These are the cases where the opponent has manage to make a random
player indifferent and the case where a purely random player is better of playing
a pure strategy.

There is importance in both results. Initially, being indifferent refers to our
actions no having any effects on the match. Thus there is not optimal behaviour
for player \(p\).

Secondly, by a pure strategy we are referring to the \(p=0\) and \(p=1\).
In this case it is know that \(p^*\) is \(\in {0, 1}\) without testing the roots
of the derivative. The optimisation problem crumbles to a binary problem.

The results are given equivalently by Lemmas~\ref{lemma:constant} and~\ref{lemma:linear}
and they are respective to the actions of the opponent. Figure~\ref{fig:purely_lemmas}
illustrates examples for both lemmas.

\begin{lemma}\label{lemma:constant}
    A given memory one player, \((q_1, q_2, q_3, q_4)\), makes a \textbf{purely
    random} player, \((p, p, p, p)\), indifferent if and only if,
    \(-q_1 + q_2 + 2q_3 - 2q_4 = 0 \) and
    \((q_2 - q_4 - 1)(q_1 - 2q_2 - 5q_3 + 7q_4 + 1) -(q_2 - 5q_4 - 1)(q_1 - q_2 - q_3 + q_4) = 0 \).
\end{lemma}

\begin{lemma}\label{lemma:linear}
    Against a memory one player, \((q_1, q_2, q_3, q_4)\), a \textbf{purely random}
    player would always play a pure strategy if and only if
    \((q_{1}q_{4} - q_{2} q_{3} + q_{3} - q_{4}) (4 q_{1} - 3 q_{2} - 4 q_{3} + 3
    q_{4} - 1) = 0\).
\end{lemma}

\begin{figure}[!htbp]
    \begin{center}
        \begin{subfigure}{0.45\textwidth}
            \includegraphics[width=\linewidth]{img/constant}
        \end{subfigure}
        \begin{subfigure}{0.45\textwidth}
            \includegraphics[width=\linewidth]{img/linear}
        \end{subfigure}
    \end{center}
    \caption{Proof of concept for Lemmas~\ref{lemma:constant},~\ref{lemma:linear}.}
    \label{fig:purely_lemmas}
\end{figure}

\section{Stability of defection}

In this section the stability of defection is explored. Defection is
known to be the dominant action in the PD and it can be proven to be the dominant
strategy for the IPD for given environments. Even so, several works have proven
that cooperation emerges in the IPD many studies around the game focus on the
emergence of cooperation. In this manuscript we try to provide a condition for when
defection is the best response in the IPD, thus when it is known that cooperation can
not occur.

Initially, let's consider equation~(\ref{eq:mo_derivative}) and let
equation~(\ref{eq:mo_derivative}) for \(p = (0, 0, 0, 0)\),

\begin{equation}\label{eq:derivative_of_quadratic_zero}
    \begin{aligned}
     \frac{du}{dp_{| p=(0, 0, 0, 0)}} & = && \frac{c \bar{a} - \bar{c}a}
      {\bar{a}^2} .\\
    \end{aligned}
\end{equation}

The numerator \(\bar{c}a - c\bar{a}\) is given by,

\[\input{tex/defection_matrix.txt}\]

and the denominator \(\bar{a} ^ 2 = (-q_2 + q_4 + 1) ^ 2\), which is always positive. In order
for defection to be the best response the derivative must have a negative
sign at the point \(p = (0, 0, 0, 0)\). That means that the utility is only
decreasing after \(p = (0, 0, 0, 0)\).

Because \(\bar{a} ^ 2\) is always positive the sign of the derivative is given by \(\bar{c}a - c\bar{a}\).
More specifically from equations,

\begin{equation}\label{eq:defection_condition_one}
    \input{tex/defection_condition_one.txt}
\end{equation}
\begin{equation}\label{eq:defection_condition_two}
    \input{tex/defection_condition_two.txt}
\end{equation}

Both signs of the partial derivatives must be negative in order for the overall
function to be decreasing, thus defection being the best response.
The signs of equations (\ref{eq:defection_condition_one}) and (\ref{eq:defection_condition_two})
vary. There are cases that they have the same sign and cases that they do not,
this is shown by numerical example summarized in Table~\ref{table:sign_of_derivative}.

\begin{table}[htbp]
\begin{center}
\begin{tabular}{cllllcc}
    \toprule
    {}& {} & {}& {}& {}&  equation(\ref{eq:defection_condition_one}) &  equation(\ref{eq:defection_condition_two}) \\
    \midrule
1 & \(q_1=\frac{3}{10}\),   & \(q_2=\frac{3}{20}\),  & \(q_3=\frac{13}{20}\), & \(q_4=\frac{7}{100}\)
&  + & + \\
2 & \(q_1=\frac{11}{25}\),  & \(q_2=\frac{3}{10}\),  & \(q_3=\frac{9}{10}\),  & \(q_4=\frac{1}{2}\)
&  - & - \\
3 & \(q_1=\frac{17}{20}\),  & \(q_2=\frac{3}{4}\),   & \(q_3=\frac{2}{5}\),   & \(q_4=\frac{1}{4}\)
&  - & + \\
4 & \(q_1=\frac{13}{88}\),  & \(q_2=\frac{21}{92}\),  & \(q_3=\frac{21}{26}\),  & \(q_4=\frac{20}{67}\)
&  + & - \\
    \bottomrule
\end{tabular}
\end{center}
\caption{Numerical examples of the derivative's sign.}
\label{table:sign_of_derivative}
\end{table}

For a tournament setting we substitute \(p = (0, 0, 0, 0)\) in
equation~(\ref{eq:mo_tournament_derivative}) which laid out:

\begin{equation}
\sum_{i=1} ^ N (c^{(i)T} \bar{a}^{(i)} - \bar{c}^{(i)T} a^{(i)})
\prod\limits_{\tiny\begin{array}{l} j=1 \\ j \neq i \end{array}} ^ N (\bar{a}^{(i)})^2
\end{equation}

The product term \(\prod\limits_{\tiny\begin{array}{l} j=1 \\ j \neq i \end{array}} ^ N (\bar{a}^{(i)})^2\)
is known to always be positive. However the sign of the sum term
\(\sum_{i=1} ^ N (c^{(i)T} \bar{a}^{(i)} - \bar{c}^{(i)T} a^{(i)})\) can vary based
on the transition probabilities of the opponents, as discussed above. A condition that
must hold in order for defection to be stable in a tournament is that the sum term
must be negative. The results are exhibited in Lemma~\ref{lemma:stability_of_defection}.

\begin{lemma}\label{lemma:stability_of_defection}
    In a tournament of \(N\) players where \(q^{(i)} = (q_{1}^{(i)}, q_{2}^{(i)}, q_{3}^{(i)}, q_{4}^{(i)})\)
    defection is known to be a best response if the transition probabilities of the
    opponents satisfy the condition:

    \begin{equation}
        \sum_{i=1} ^ N (c^{(i)T} \bar{a}^{(i)} - \bar{c}^{(i)T} a^{(i)}) <= 0.
    \end{equation}
\end{lemma}

Moreover lets us consider a constrained version of the problem once again. Lets us
assume that in an pairwise interaction the opponent is a reactive player \(q=(q_1, q_2, q_1, q_2)\).
By substituting \(q_3=q_1\) and \(q_4=q_2\) equations (\ref{eq:defection_condition_one})
and (\ref{eq:defection_condition_two}) are now re written as follow,

\[\left[\begin{matrix}- q_{2} \left(4 q_{1} - 5 q_{2} - 1\right)\\
\left(q_{2} - 1\right) \left(4 q_{1} - 5 q_{2} - 1\right)\end{matrix}\right]\]

The sign of both equations is now based on the same term,\(\left(4 q_{1} - 5 q_{2} - 1\right)\),
which is a term that can have both negative and positive values. This is shown
by Figure~\ref{fig:sign_against_reactive}. Following this the following result is retrieved,

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.45\linewidth]{img/sign_against_reactive.pdf}
      \caption{Sign of \(\left(4 q_{1} - 5 q_{2} - 1\right)\).}
      \label{fig:sign_against_reactive}
  \end{figure}

\begin{lemma}
Defection is the best responses of a memory one player \(p\) against a reactive
player \(q\) if the transition probabilities of the opponent satisfy the
condition:

\begin{equation}
    4 q_{1} - 5 q_{2} - 1 > 0
\end{equation}
\end{lemma}

\section{Optimisation against memory one strategies}\label{section:optimisation_memone}

The main aim of this work is to capture best response memory one strategies.
Though an analytical approach can not be applied further than discussed in
Section~\ref{section:best_response_mem_one} an empirical approach is considered here.
More specially, the optimisation problem of (\ref{eq:mo_tournament_optimisation})
is maximized using bayesian optimisation. Bayesian optimisation is a
global optimisation algorithm, introduced in~\cite{Mokus1978}, which has proven to
outperform many other popular algorithms~\cite{Jones2001}.

As many other algorithms bayesian optimisation is used to find the maximum of a
function \(f\) on some bounded set. Bayesian constructs a probabilistic
model for \(f\) and then exploits this model to make decisions about where in the
bounded set to next evaluate the function. It relays on the previous
of \(f\) and not simply rely on local gradient and Hessian approximations.
This allows the algorithm to optimise a non concave function with relatively few
evaluations, at the cost of performing more computation to determine the next point
to try~\cite{snoek2012}.

The open source package~\cite{Head2018} offers an implementation of bayesian optimisation
and is used in this paper to compute a large number of best memory one responses against
sets of random memory one strategies. The implementation of bayesian in~\cite{Head2018}
allows us to perform the algorithm for a different combination of parameters.
The parameters explored here are:

\begin{itemize}
    \item Number of calls, maximum number of calls to the objective function.
    \item Number of random starts, number of evaluations of the objective function
    with random points before approximating it.
\end{itemize}

The different parameters' combinations and their respective values are laid out in
Table~\ref{table:ba_opt}.

\begin{table}[htbp]
\begin{center}
\begin{tabular}{ccc}
    \toprule
    {} &  number of calls & number of random starts\\
    \midrule
    1 & 20 & 10 \\
    2 & 30 & 20 \\
    3 & 40 & 20 \\
    4 & 45 & 20 \\
    5 & 50 & 20 \\
    \bottomrule
\end{tabular}
\end{center}
\caption{Bayesian optimisation sets of parameters' values.}
\label{table:ba_opt}
\end{table}

Note that another global optimization algorithm called differential evolution~\cite{Storn1997}
was also reviewed for the purpose of this paper. Bayesian optimization was
chosen over differential evolution due to a high computational cost.

The combination that was chosen to carry out the empirical trials is that
of 50 number of calls and 20 number of random starts. This set of parameters
was determined to be the most efficient using best reactive responses as an experimental
case.

A total of 9900 different memory one opponents were randomly generated and bayesian optimisation
was used to find the optimal reactive strategy. The results were compared to that of
Lemma~\ref{lemma:reactive_best_response} which we know exhibits the best reactive response.
The particular parameters' set was the set with
the smallest difference between the two captured best behaviours.
The results of this comparison are presented by Table~\ref{table:bayesian_excact_difference}.

\begin{table}[htbp]
    \begin{center}
    \input{tex/bayesian_proof.txt}
    \caption{Difference of \(u_q(p)\) for \(p \in \R_{[0, 1]} ^ 2\). The difference was
    calculated as exact \(u_q(p ^ *)\) minus Bayesian \(u_q(\tilde{p} ^ *)\).}
    \label{table:bayesian_excact_difference}
    \end{center}
\end{table}

Thus it can be confirmed that bayesian optimisation manages to capture the optimal
behaviour of reactive strategies. The very same set of parameters was used to optimise
memory one strategies against single opponents and against
sets of \(N=2\) opponents. \(N=2\) was chosen because is the smallest \(N\) for
which there is a multi opponent interaction. For each \(N=1\) and \(N=2\) opponents a
total of 1022 best responses of memory one strategies have been captured. This data has
been archived in.
% TODO: add ZD after our paper is on pre-print?!

\section{Limitation of memory}

The third and final part of this paper focuses on proving that short memory strategies
have limitations. Though it has been proven~\cite{Press2012} that there exists a set
of memory one strategies that can outperform any opponent, this was done only for
the case of \(N=1\). In this section we introduce several empirical results that
show that more complex strategies can indeed perform better in cases of \(N=2\).
This is achieved by comparing the performance of an optimised memory one strategy
to that of a trained long memory one.

The long memory strategies are trained using bayesian algorithm as the one described in
Section~\ref{section:optimisation_memone}. The trained strategy used is a strategy called Gambler,
introduced and discussed in~\cite{Harper2017}, and the objective function of a Gambler
is the average performance in a tournament of 200 turns and 50 repetitions.

\subsection{Gambler}

Several ways of representing IPD strategies have been used over the years.
In~\cite{Harper2017} several of those `archetypes' are presented
and used to train different successful strategies. One of the archetypes firstly
introduced in that paper is Gambler. Gambler is based on a lookup table and encodes
a probability of cooperating based on the opponent's first \(n_1\) moves, the opponent's
last \(m_1\) moves, and the players last \(m_2\) moves.

Several variants of Gambler have been trained for this work (Table~\ref{table:gambler}).
In essence Gambler can represent any generic strategy
and that is why it has been chosen.

\begin{table}[htbp]
    \begin{center}
    \begin{tabular}{clllll}
        \toprule
        {}&  \(n_1\) & \(m_1\) & \(m_2\)\\
        \midrule
        1 & 1 & 1 & 2\\
        2 & 2 & 2 & 0\\
        3 & 2 & 2 & 1\\
        4 & 2 & 2 & 2\\
        5 & 4 & 4 & 4\\
        \bottomrule
    \end{tabular}
    \end{center}
    \caption{Variants of Gambler used.}
    \label{table:gambler}
\end{table}

\subsection{Empirical Results}

The performance of the memory one and Gamblers strategies are compared for cases of
\(N=1\) and \(N=2\). The following steps are taken:

\begin{enumerate}
    \item An \(N\) number of random opponents are generated.
    \item Using (\ref{eq:mo_tournament_optimisation}) \(p^*\) for that given environment is captured.
    \item A Gambler type (each variant of Table~\ref{table:gambler}) is trained for the same environment.
    \item Both utilities of the optimised and the trained strategy are reordered.
\end{enumerate}

A large data set containing the opponents as well as the optimised/trained behaviours
can be found in. %TODO archive
The number of experimental cases for each Gambler are displayed in Table~\ref{table:number_of_trials_per_gambler}.
Note that a number of 1022 trials corresponds to 1022 trials for \(N=1\) and 1022
trials for \(N=2\).

\begin{table}[htbp]
    \begin{center}
    \input{tex/gambler_number_of_trials.txt}
    \caption{Number of trials, for \(N=1\) and \(N=2\), for each Gambler instance.}
    \label{table:number_of_trials_per_gambler}
    \end{center}
\end{table}

The results are explored by studying the difference between
\(\frac{1}{N} \sum\limits_{i=1} ^ {N} {u_q}^{(i)} (p ^ *)\) and
\(\frac{1}{N} \sum\limits_{i=1} ^ {N} {U_q}^{(i)} (G)\) ,
where \(U(G)\) represents the utility of a Gambler. The results are illustrated in
Figure~\ref{fig:boxplots}.

For the cases of Gambler \(n_1=1, m_1=1, m_2=2\), \(n_1=2, m_1=2, m_2=0\) and
\(n_1=2, m_1=2, m_2=1\), though there are few edges cases, the difference distribution
is congregated around zero. For the rest of the Gambler's types there nce is mainly worse.
This could be a result of the Gamblers not being trained for long enough. Thus a larger
number of calls should be used. % Currently running more.

Furthermore, there is no significant difference between the distributions of
\(N=1\) and \(N=2\). This was checked by performing \(T-\)test for the means of two
samples. The calculated \(p-\) values are presented in Table~\ref{table:p_values}.

\begin{table}
    \begin{center}
    \begin{tabular}{llr}
        \toprule
        {} &       Gamblers &  \(p-\) values \\
        \midrule
        0 &  Gambler 1\_1\_2 &              0.242 \\
        1 &  Gambler 2\_2\_0 &              0.214 \\
        2 &  Gambler 2\_2\_1 &              0.179 \\
        3 &  Gambler 2\_2\_2 &              0.629 \\
        4 &  Gambler 4\_4\_4 &              0.141 \\
        \bottomrule
    \end{tabular}
    \caption{\(p-\) values for the means of \(N=1\) to \(N=2\) using \(T-\)tests.}
    \label{table:p_values}
    \end{center}
\end{table}

There appears to be no significant difference between complex and memory one strategies.
The difference in performance is mainly congregated around zero, and that is true for both
cases of \(N=1\) and \(N=2\). However, that there is indication that
complex strategies can outperform memory one strategies for \(N=2\).There
are cases that they have a difference in score of 0.5.

\begin{figure}
    \centering
    \begin{subfigure}{0.30\textwidth}
        \centering
        \includegraphics[width=\textwidth]{"img/Gambler 1_1_2_boxplot"}
    \end{subfigure}
    \begin{subfigure}{0.30\textwidth}
        \centering
        \includegraphics[width=\textwidth]{"img/Gambler 2_2_0_boxplot"}
    \end{subfigure}
    \begin{subfigure}{0.30\textwidth}
        \centering
        \includegraphics[width=\textwidth]{"img/Gambler 2_2_1_boxplot"}
    \end{subfigure}
    \begin{subfigure}{0.30\textwidth}
        \centering
        \includegraphics[width=\textwidth]{"img/Gambler 2_2_2_boxplot"}
    \end{subfigure}
    \begin{subfigure}{0.30\textwidth}
        \centering
        \includegraphics[width=\textwidth]{"img/Gambler 4_4_4_boxplot"}
    \end{subfigure}
    \caption{Difference between \(\frac{1}{N} \sum\limits_{i=1} ^ {N} {u_q}^{(i)} (p ^ *)\)
    and  \(\frac{1}{N} \sum\limits_{i=1} ^ {N} {U_q}^{(i)} G\) for \(N=1\) and \(N=2\).}
    \label{fig:boxplots}
\end{figure}

\section{Discussion}

In this framework, memory one strategies for the well known game the IPD were
studied. These are strategies that utilize a single slot of memory to define their
next action. An analytical formulation for retrieving the payoffs of memory one
strategies against memory one strategies was used here. Though the analytical
formulation has been previously use, this manuscript is the first to prove that the payoff
of a such a player \(p\) has a compact form and proved that is a non concave
function. Furthermore, best memory one responses were exploit as an optimisation
problem of a ratio of quadratic forms.

We have managed to prove that for reactive and purely random strategies
that best responses can be captured analytically. This was done using using algebraic
approaches such as companion matrices and resultant theory. We investigated the
stability of defection and proved that environments for which cooperation will
never emerge can be recognised immediately by the transitions of the opponents.

Finally,  we generated a large date set of bests memory one responses for \(N=1\) and
\(N=2\). The limitations of memory were tried to be shown by comparing the performance
of best memory one strategies to that of more complex strategies. Though there are
indications that complex strategies indeed perform better, the significant of the
difference is in question. More experimental trials and exploration will be
carried out.

\appendix
\input{tex/appendix_tables}
\input{tex/appendix_algorithms}

% Bibliography
\bibliographystyle{plain}
\bibliography{bibliography.bib}

\end{document}

