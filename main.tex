\documentclass[10pt]{article}

% Manage page layout
\usepackage[margin=2.5cm, includefoot, footskip=30pt]{geometry}
\pagestyle{plain}
\setlength{\parindent}{0em}
\setlength{\parskip}{1em}
\renewcommand{\baselinestretch}{1}

%%%%%%%PACKAGES HERE%%%%%%%
\usepackage{tikz}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{standalone}

\newcommand{\R}{\mathbb{R}}
\newtheorem{theorem}{Theorem}
\usetikzlibrary{decorations.pathmorphing, decorations.pathreplacing, angles,
                quotes, calc, er, positioning}
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{Memory size in the Prisoner's Dilemma}
\author{Nikoleta E. Glynatsi \and Vincent Knight}
\date{}

\begin{document}

\maketitle

\begin{abstract}

The two player Iterated Prisoner's Dilemma is a fundamental iterated game used
for studying the emergence of cooperation. The two players interact repeatedly
and they have the ability to adopt strategies. A strategy allows a player to map
the outcomes of the previous interactions to an action. A set of strategies that
consider only the outcome of the previous round are called memory one. These
players gain attention after a publication in 2012 that showed that a memory one
strategy can manipulate its opponent.

In this manuscript we build upon a framework provided in 1989 for the study of
these strategies and identify the best responses of memory one players. The aim
of this work is to show the limitations of memory one strategies in multi-opponent
interactions. A number of theoretic results are presented.
%TODO: Expand when we get results
\end{abstract}

\section{Introduction}\label{section:introduction}

The Prisoner's Dilemma (PD) is a two player person game used in understanding the
evolution of co-operative behaviour. Each player can choose between cooperation
(C) or defection (D). The decisions are made simultaneously and independently.
The normal form representation of the game is given by:

\begin{equation}\label{equ:pd_definition}
    S_p = \begin{pmatrix}
    R & S  \\
    T & P
    \end{pmatrix} \quad
    S_q = \begin{pmatrix}
        R & T  \\
        S & P
        \end{pmatrix}
\end{equation}

where \(S_p\) represents the utilities of the first player and \(S_q\) the utilities
of the second player. The payoffs, \((R, P, S, T)\), are constrained by equations
(\ref{eq:pd_constrain_one}) and~(\ref{eq:pd_constrain_two}). Constrain
(\ref{eq:pd_constrain_one}) ensures that defection dominates cooperation and
constrain (\ref{eq:pd_constrain_two}) ensures that there is a dilemma. Because
the sum of the utilities for both players is better when both choose cooperation.
The most common values used in the literature are \((3, 1, 0, 5)\)~\cite{Axelrod1981}.

\begin{equation}\label{eq:pd_constrain_one}
    T > R > P > S 
\end{equation}

\begin{equation}\label{eq:pd_constrain_two}
    2R > T + S
\end{equation}

The PD is a one shot game, however it is commonly studied in a manner where the
history of the interactions matters. The repeated form of the game is called the
Iterated Prisoner's Dilemma (IPD) and in the 1980s following the work of
\cite{Axelrod1980a, Axelrod1980b} it attracted the attention of the scientific
community.

In~\cite{Axelrod1980a} a computer tournament of the IPD was performed. A
tournament is a series of rounds of the IPD between pairs of strategies. The
topology commonly used, \cite{Axelrod1980a, Axelrod1980b}, is that of a round
robin where all contestants compete against each other. The winner of these
tournament was decided on the average score and not in the number of wins.

These tournaments were the milestones of an era which to today is using
computer tournaments to explore the robustness of strategies of IPD. Though
the robustness can also be checked through evolutionary process~\cite{Nowak}.
However, this aspect will not be considered here, instead the focus is on
performance in tournaments.

In Axelrod's original tournaments \cite{Axelrod1980a, Axelrod1980b}, strategies
were allowed access to the history and in the first tournament they also knew
the number of total turns in each interaction. The history included the
previous moves of both the player and the opponent. How many turns of history
that a strategy would ue, the memory size, was left to the creator of the
strategy to decide. For example the winning strategy of the first tournaments,
Tit for Tat was a strategy that made use of the previous move of the opponent
only. Tit for Tat is a strategy that starts by cooperating and then mimics the
previous action of it's opponent. Strategies like Tit for Tat are called memory
one strategies. A framework for studying memory one strategies was introduced
in~\cite{Nowak1989} and further used in~\cite{Nowak1993, Nowak1990}.

In~\cite{Press2012} Press and Dyson, introduced a new set of memory one
strategies called zero determinant (ZD) strategies. The ZD strategies,
manage to force a linear relationship between the score of the strategy
and the opponent. Press and Dyson, prove their concept of the ZD strategies
and claim that a ZD strategy can outperform any given opponent.

The ZD strategies have tracked a lot of attention. It was stated that
``Press and Dyson have fundamentally changed the viewpoint on the Prisoner's
Dilemma''~\cite{Stewart2012}. In~\cite{Stewart2012}, the Axelrod's
tournament have been re-run including ZD strategies and a new set of ZD
strategies the Generous ZD. Even so, ZD and memory one strategies have
also received criticism. In~\cite{Harper2015}, the `memory of a strategy does
not matter' statement was questioned. A set of more complex strategies,
strategies that take in account the entire history set of the game, were
trained and proven to be more robust than ZD strategies.

\subsection{Background}

A memory one strategy \(p\) in a match against a strategy \(q\) would decide it's
action in turn \(m\) based on what occurred in turn \(m - 1\). If a strategy is concerned with only the outcome
of a single turn then there are four possible `states' the strategy could be in.
These are \(CC, CD, DC,CC\). A memory one strategy is denoted by the probabilities
of cooperating after each of these states, \(p=p_1, p_2, p_3, p_4 \in \R_{[0,1]} ^ 4\) 

\begin{figure}
    \centering
    \begin{subfigure}{0.45\textwidth}
        \includestandalone[width=.6\textwidth]{tex/states}
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
        \includestandalone[width=.85\textwidth]{tex/markov_chain}
    \end{subfigure}
\end{figure}

In 1989 a framework was introduced by to study the interactions of memory
strategies.

- the mathematics
- the state states 
- examples

As described in~\cite{Nowak1990}, a match between players \(p\) and \(q\)
can be modelled as a stochastic process, where the players move from state to 
state. More specifically, it can be modelled by the use of a Markov process of
four states. The transition probability matrix is defined as \(M\) and is given
by,

\begin{equation}\label{eq:m_matrix}
    \input{tex/m_matrix.tex}.
\end{equation}

Let \(v\) be the vector of the stationary probabilities of \(M\) and \(S_p\)
payoff vector of player \(p\). The states of vector \(v\) are given in the
Appendix. The scores of each player can be
retrieved by multiplying the probabilities of each state, at the stationary state,
with the equivalent payoff. Thus, the  utility for player \(p\) against \(q\),
denoted as \(u_q(p)\), is defined by,

\begin{equation}\label{eq:press_dyson_utility}
    u_q(p) = v \times S_p.
\end{equation}

\subsection{Problem Description}

The purpose of this work is to consider a given memory one strategy 
\(p=(p_1, p_2, p_3, p_4)\), (in a similar fashion to~\cite{Press2012}). However
whilst~\cite{Press2012} found a way for the opponent of \(p\) to manipulate 
\(q\), this work will consider an optimisation approach to identify the best 
response \(p^*=(p_1, p_2, p_3, p_4)\) to a strategy \(q\). In essence 
answering the question: what is the best memory one strategy against a given 
memory one strategy.

This approach is then be expanded on to consider multiple players \(q^{(1)},
q^{(2)}, \dots ,q^{(N)}\) which in turn allows for the optimisation  of a given memory
one strategy in a group of memory one strategies. Along the way a number of
theoretic results will be proven:

\begin{itemize}
    \item The utility of a given player \(p\) against a given opponent \(q\) 
    is a ratio of quadratic forms.
    \item For given structural constraints on \(p\) (\(p_1=p_2=p_3=p_4\)) a number
    of theoretic conditions are found to allow for further categorization of the
    utility of \(p\).
    \item Optimization procedures, often reducing the complex optimisation 
    problem to a search over a small finite set are found.
    \item Cases where defection is stationary.
\end{itemize}

\section{Utility}

\begin{theorem}\label{theorem:quadratic_form_u}
    For a given memory one strategy \(p\in\mathbb{R}_{[0,1]}^4\) playing another 
    memory one strategy \(q\in\mathbb{R}_{[0,1]}^4\), the 
    utility of the player \(u_q(p)\) can be re written as a ratio of two quadratic
    forms:
    
    \begin{equation}\label{eq:optimisation_quadratic}
    u_q(p) = \frac{\frac{1}{2}p^TQp + c^Tp + a}
                {\frac{1}{2}p^T\bar{Q}p + \bar{c}^Tp + \bar{a}}, 
    \end{equation}
    where \(Q, \bar{Q}\) are matrices of \(4 \times 4\) defined with the transition
    probabilities of the opponent's transition probabilities \(q_1, q_2, q_3, q_4\).
    
    \begin{center}
    \begin{equation}
    \resizebox{0.9\linewidth}{!}{\arraycolsep=2.5pt%
    \boldmath\(
    Q = \input{tex/q_numerator}\)},
    \end{equation}
    \begin{equation}\label{eq:q_bar_matrix}
    \resizebox{0.8\linewidth}{!}{\arraycolsep=2.5pt%
    \boldmath\(
    \bar{Q} =  \input{tex/q_denominator}\)}.
    \end{equation}
    \end{center}
    
    \(c \text{ and } \bar{c}\), are \(4 \times 1\) vectors defined by the transition rates 
    \(q_1, q_2, q_3, q_4\).
    
    \begin{equation}\label{eq:q_matrix_numerator}
    \resizebox{0.3\linewidth}{!}{\arraycolsep=2.5pt%
    \(c = \input{tex/c_numerator}\),}
    \end{equation}
    \begin{equation}\label{eq:q_matrix_denominator}
    \resizebox{0.3\linewidth}{!}{\arraycolsep=2.5pt%
    \(\bar{c} = \input{tex/c_denominator}\).
    }
    \end{equation}
    
    Lastly, \(a = \input{tex/numerator_constant}\) and 
    \(\bar{a} = \input{tex/denominator_constant}\).
    \end{theorem}

\subsection{Validation}

All results are validated using~\cite{axelrodproject} which is an open research
framework for the study of the Iterated Prisoner's Dilemma. This package is
described in~\cite{Knight2016}.

To validate the formulation of \(u_q(p)\) several memory one players were 
matched against 20 opponents. Note that the payoff values  used hereafter in this
work are \((3, 1, 0, 5)\). 
The simulated value of \(u_q(p)\) has been calculated using \cite{axelrodproject}
and the theoretical by  substituting in equation~(\ref{eq:optimisation_quadratic}).
In Figure~\ref{fig:analytical_simulated}, both the simulated and the theoretical
value of \(u_q(p)\), against each opponent, are plotted for three different memory
one strategies. Figure \ref{fig:analytical_simulated} indicates that the 
formulation of \(u_q(p)\) as a quadratic ratio successfully captures the 
simulated behaviour.

\begin{figure}[!htbp]
\begin{center}
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\linewidth]{img/validation_img_two.png}
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
        \includegraphics[width=\linewidth]{img/validation_img_three.png}
    \end{subfigure}
\end{center}
\caption{Differences between simulated and analytical results.}
\label{fig:analytical_simulated}
\end{figure}

\section{Proximate of best responses}

The analytical formulation gives the advantage of time. That is because the 
payoffs of a match between two opponents are now retrievable without 
simulating the actual match itself. Utility \(u_q(p)\) can 
now be calculated numerically instead of using simulation. In the introduction 
a question was raised: which memory one strategy is the \textbf{best response}
against another memory one? This will be considered as an optimisation problem,
where a memory one strategy \(p\) wants to optimise it's utility \(u_q(p)\)
against an opponent \(q\). The decision variable is the vector \(p\) and the 
solitary constrains \(p \in \R^4_{[0, 1]} \). The optimisation problem is 
given by~(\ref{eq:mo_optimisation}).

\begin{equation}\label{eq:mo_optimisation}
\begin{aligned}
& \max_p: && \frac{\frac{1}{2}  p  Q  p^T + c^T p + a} 
                  {\frac{1}{2}  p  \bar{Q}  p^T + \bar{c}^T  p + \bar{a}}
\\
& \text{such that}: && \ p \in \R^4_{[0, 1]}.
\end{aligned}
\end{equation}

\subsection{In purely random strategies}

% Notebooks A.0.7.1- A.0.7.3
In this section we explore a simplified version of the main problem. A set of 
memory one strategies where the transition probabilities of each state are the 
same, are called \textbf{purely random strategies}. 
as

The optimisation problem of (\ref{eq:mo_optimisation}) now has an extra constraint
and is re written as,

\begin{equation}\label{eq:random_optimisation}
\begin{aligned}
\max_p: & \ u_q(p)
\\
\text{such that}: & \ p_1 = p_2 = p_3 = p_4 = p\\
    & \ 0 \leq p \leq 1. 
\end{aligned}
\end{equation}


\subsection{In memory one strategies}

\section{Stability of defection}

\section{Numerical experiments}

% Bibliography
\bibliographystyle{plain}
\bibliography{bibliography.bib}

\end{document}